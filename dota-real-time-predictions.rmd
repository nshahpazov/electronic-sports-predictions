---
title: "Dota"
author: "Nikola Shahpazov"
date: "12/3/2020"
output: html_document
---

```{r package-setup, message=FALSE, warning=FALSE, include=FALSE, results='hide'}
## Create the list of required packages
list.of.packages <- c(
  # utility libraries
  "Metrics",
  "reshape",
  "glue",
  "tidyverse",
  "caret",
  "recipes",
  "purrr"
)

new.packages <- list.of.packages[(!list.of.packages %in% installed.packages() |
                                    list.of.packages %in% old.packages()[ ,"Package"])]

if (length(new.packages)) {
  install.packages(new.packages, repos = "http://cran.us.r-project.org")
}

## Load all necessary packages in RAM (working environment)
lapply(list.of.packages, require, character.only = TRUE)

rm(list.of.packages, new.packages)
```

```{r constants}
WINDOW_COLS <- c("gold_difference", "xp_difference", "lh_difference")
NBIN <- 8
```

```{r load-inner-modules}
source("helpers.R")
source("markov-chains-helpers.R")
```

### Loading data
```{r load-data}
matches_df <- read.csv(
  "./data/match.csv",
  colClasses = c(radiant_win = "logical")
)

time_df <- read.csv('./data/player_time.csv')
```

### Preprocessing

```{r prepare-data}
diffs_by_time_df <- time_df %>%
  mutate(minute = times / 60) %>%
  filter(minute <= 100) %>%
  mutate(gold_difference = diff_means(., "gold_t_[0-4]$", "gold_t_1[2-3]")) %>%
  mutate(xp_difference = diff_means(., "xp_t_[0-4]$", "xp_t_1[2-3]")) %>%
  mutate(lh_difference = diff_means(., "lh_t_[0-4]$", "lh_t_1[2-3]")) %>%
  select(match_id, minute, gold_difference, xp_difference, lh_difference) %>%
  pivot_wider(id_cols = "match_id", names_from = "minute",
              values_from = WINDOW_COLS) %>%
  select(-gold_difference_0, -xp_difference_0, -lh_difference_0) %>%
  left_join(select(matches_df, match_id, radiant_win),
            by = "match_id") %>%
  mutate(radiant_win = as.factor(radiant_win))
```

### Train set and Test set split

```{r test-train-split}
train_indices <- createDataPartition(
  diffs_by_time_df$radiant_win,
  p = .8,
  list = FALSE,
  times = 1
)

train_set <- diffs_by_time_df[train_indices, ]
test_set <- diffs_by_time_df[-train_indices, ]
```

### Train various logistic regression models

```{r train-time-windows-lr, include=FALSE}
tc <- trainControl(method = "cv", number = 3)

train_set_std <- standardize_time_df(train_set)
test_set_std <- standardize_time_df(test_set)

# slr_gld <- train_lr(data = train_set_std, cols = WINDOW_COLS[1], control = tc)
slr_glh <- train_lr(data = train_set_std, cols = WINDOW_COLS[-2], control = tc)

lr_models <- list(
  # "slr_gld" = slr_gld,
  "slr_glh" = slr_glh
)
```

### Explore Cross Validation Test Accuracy

```{r plot-cv-acuracy}
lr_models %>%
  map(~imap(., ~.$results$Accuracy)) %>%
  imap(~data.frame(accuracy = unlist(.), time = 6:101, model = .y)) %>%
  bind_rows() %>%
  ggplot(mapping = aes(x = time, y = accuracy, color = model)) +
  geom_line() +
  ggtitle("Training set CV Accuracy")
```

We see that SLR with gold and last hits (gold is correlated with xp) behaves the best till the 
80th minute and after that it starts oscillating a lot, probably because 
there aren't a lot of matches then, or the matches are very even.

```{r prediction-accuracies}
test_performance <- lr_models %>%
  imap(
    ~data.frame(
      accuracy = get_test_accuracies(., test_set_std, interval = 1:20),
      time = 1:20,
      model = .y
    )
  ) %>%
  bind_rows()

test_performance %>%
  ggplot(mapping = aes(x = time, y = accuracy, color = model)) +
  geom_line() +
  ggtitle("Test Set Accuracy")
```
We see that the test accuracy behaves similarly to the test set cv accuracy from above.

### Markov Chains Model
```{r markov-chain-model, message=FALSE, warning=FALSE}
# create winners transition matrix
winners_tm <- train_set %>%
  filter(as.logical(radiant_win)) %>%
  as_binned_matrix(nbin = NBIN) %>%
  construct_transition_matrix(nbin = NBIN)

# create losers transition matrix
losers_tm <-  train_set %>%
  filter(!as.logical(radiant_win)) %>%
  as_binned_matrix(nbin = NBIN) %>%
  construct_transition_matrix(nbin = NBIN)

# plot winners transition matrix
winners_tm %>%
  matrix_to_df() %>%
  ggplot(mapping = aes(row, col, fill = value)) +
    geom_tile() +
    geom_text(aes(label = round(value, 1))) +
    ggtitle("Transition changes for the Winning team in the train set") +
    xlab("Gold Bin States") +
    ylab("Gold Bin States")

# plot losers transition matrix
losers_tm %>%
  matrix_to_df() %>%
  ggplot(mapping = aes(row, col, fill = value)) + 
    geom_tile() +
    geom_text(aes(label = round(value, 1))) +
    ggtitle("Transition changes for the Losing team in the train set") +
    xlab("Gold Bin States") +
    ylab("Gold Bin States")
```


### Markov Chain model with a PCA-generated state space
```{r markov-pca, include=FALSE}
pca_data <- diffs_by_time_df %>%
  standardize_time_df() %>%
  pca_transform(cols = WINDOW_COLS[-2])

pca_data$match_id <- diffs_by_time_df$match_id
pca_data$radiant_win <- diffs_by_time_df$radiant_win

pca_train_set <- pca_data[train_indices, ]
pca_test_set <- pca_data[-train_indices, ]

winners_pca_tm <- pca_train_set %>%
  filter(as.logical(radiant_win)) %>%
  as_binned_matrix(nbin = NBIN, feature = "pc") %>%
  construct_transition_matrix(nbin = NBIN)

# create losers transition matrix for pca data
losers_pca_tm <-  pca_train_set %>%
  filter(!as.logical(radiant_win)) %>%
  as_binned_matrix(nbin = NBIN, feature = "pc") %>%
  construct_transition_matrix(nbin = NBIN)

winners_pca_tm %>%
  matrix_to_df() %>%
  ggplot(mapping = aes(row, col, fill = value)) + 
    geom_tile() +
    geom_text(aes(label = round(value, 1))) +
    ggtitle("Transition changes for the winning team in the train set") +
    xlab("PCA Bin States") +
    ylab("PCA Bin States")

losers_pca_tm %>%
  matrix_to_df() %>%
  ggplot(mapping = aes(row, col, fill = value)) + 
    geom_tile() +
    geom_text(aes(label = round(value, 1))) +
    ggtitle("Transition changes for the losing team in the train set") +
    xlab("PCA Bin States") +
    ylab("PCA Bin States")
```

```{r markov-chains-model-predictions, echo=FALSE}
tsbm <- as_binned_matrix(test_set, nbin = NBIN)
tsbm_pca <- pca_test_set %>% as_binned_matrix(nbin = NBIN, feature = "pc")

pca_mc_accuracies <- data.frame(
  accuracy = unlist(imap(1:80, ~acc(test_set, tsbm_pca, winners_pca_tm, losers_pca_tm, .x))),
  time = 1:80,
  model = "MC PCA"
)

mc_accuracies <- data.frame(
  accuracy = unlist(imap(1:80, ~acc(test_set, tsbm, winners_tm, losers_tm, .x))),
  time = 1:80,
  model = "MC"
)

benchmark_accuracies <- test_set %>%
  mutate_at(vars(starts_with("gold")), ~as.numeric((. > 0) == radiant_win)) %>%
  summarise_at(vars(starts_with("gold")), mean, na.rm = TRUE) %>%
  pivot_longer(cols = gold_difference_1:gold_difference_100,
               values_to = "accuracy") %>%
  mutate(time = 1:100, model = "Benchmark")

bind_rows(
  # test_performance[1:80, ],
  mc_accuracies,
  pca_mc_accuracies,
  benchmark_accuracies
) %>%
ggplot(mapping = aes(x = time, y = accuracy, color = model)) +
geom_line() +
ggtitle("Test Set Accuracy")
```

```{r nbe}


```

### Notes

* Tried reflecting losers and winners but it brought little to the table

* We tried segmenting the markov chain models into different categories. When predicting
for a minute we use a model for which is trained on games longer than that minute
This didn't improve anything, probably because the gold transition changing is more
important in early stages of the game.

* Tried different quantile bins for the gold states and seems that 8 gives better results than 10

* Tried PCA on a transformation of gold and last hits but the Markov Chain seems to be performing slightly worse than the original
